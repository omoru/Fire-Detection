{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "##########################################################\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense\n",
        "from tensorflow.keras.applications import vgg16\n",
        "from tensorflow.keras.optimizers import Adam, SGD\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import scipy  #Used to upsample our image\n",
        "\n",
        "import os\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from keras.applications.vgg16 import preprocess_input"
      ],
      "metadata": {
        "id": "zMGIaL02R6xg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#Define the model. \n",
        "#Here, we use pre-trained VGG16 layers and add GlobalAveragePooling and dense prediction layers.\n",
        "#You can define any model. \n",
        "#Also, here we set the first few convolutional blocks as non-trainable and only train the last block.\n",
        "#This is just to speed up the training. You can train all layers if you want. \n",
        "def get_model(input_shape = (224,224,3)):\n",
        "    \n",
        "    vgg = vgg16.VGG16(weights='imagenet', include_top=False, input_shape = input_shape)\n",
        "\n",
        "    #for layer in vgg.layers[:-8]:  #Set block4 and block5 to be trainable. \n",
        "    for layer in vgg.layers[:-5]:    #Set block5 trainable, all others as non-trainable\n",
        "        print(layer.name)\n",
        "        layer.trainable = False #All others as non-trainable.\n",
        "\n",
        "    x = vgg.output\n",
        "    x = GlobalAveragePooling2D()(x) #Use GlobalAveragePooling and NOT flatten. \n",
        "    x = Dense(2, activation=\"softmax\")(x)  #We are defining this as multiclass problem. \n",
        "    \n",
        "    model = Model(vgg.input, x)\n",
        "    model.compile(loss = \"categorical_crossentropy\", \n",
        "                  optimizer = SGD(learning_rate=0.0001, momentum=0.9),\n",
        "                  metrics=[\"accuracy\"])\n",
        "    \n",
        "    return model\n",
        "\n",
        "model = get_model(input_shape = (224,224,3))\n",
        "print(model.summary())\n"
      ],
      "metadata": {
        "id": "ankeiFhtTdQn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "directory = '/content/drive/MyDrive/Fire Dataset PCD/'\n",
        "batch_size = 16\n",
        "target_size = (224,224)\n",
        "\n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
        "\n",
        "train_generator=datagen.flow_from_directory(\n",
        "    directory=directory + 'Train',\n",
        "    batch_size=batch_size,\n",
        "    target_size= target_size)\n",
        "\n",
        "\n",
        "validation_generator=datagen.flow_from_directory(\n",
        "    directory=directory + 'Test',\n",
        "    batch_size=batch_size,\n",
        "    target_size= target_size)\n"
      ],
      "metadata": {
        "id": "vL43PBE1Xs9x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(train_generator,\n",
        "                    epochs=1,\n",
        "                    validation_data = validation_generator,\n",
        "                    verbose = 1)\n",
        "#plot the training and validation accuracy and loss at each epoch\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(1, len(loss) + 1)\n",
        "plt.plot(epochs, loss, 'y', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "plt.plot(epochs, acc, 'y', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'r', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "###############################################################\n",
        "\n",
        "# #Check model accuracy on the test data\n",
        "# _, acc = model.evaluate(X_test, y_test)\n",
        "# print(\"Accuracy = \", (acc * 100.0), \"%\")\n"
      ],
      "metadata": {
        "id": "hIVdl2A6Ypxp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = model.evaluate(test_generator, steps= test_generator.samples // batch_size, verbose=1)\n",
        "print('test acc:', test_acc)"
      ],
      "metadata": {
        "id": "kS9jezm9iCVh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fuegoen=[]\n",
        "from matplotlib.patches import Rectangle #To add a rectangle overlay to the image\n",
        "from skimage.feature.peak import peak_local_max  #To detect hotspots in 2D images. \n",
        "def plot_heatmap(filename,orig_img,img):\n",
        "    fig = plt.figure(figsize=[1,1])\n",
        "    # This is to get rid of the axes and only get the picture \n",
        "    ax = fig.add_subplot(111)\n",
        "    ax.axes.get_xaxis().set_visible(False)\n",
        "    ax.axes.get_yaxis().set_visible(False)\n",
        "    ax.set_frame_on(False)\n",
        "    #Get output from the last conv. layer\n",
        "    vgg = Model(inputs =model.input, outputs = (model.output,model.get_layer(\"block5_conv3\").output))\n",
        "  \n",
        "    pred,last_conv_output = vgg.predict(np.expand_dims(img, axis=0))\n",
        "    last_conv_output = np.squeeze(last_conv_output)\n",
        "\n",
        "    pred_class = np.argmax(pred)\n",
        "    if pred_class == 1:\n",
        "       plt.imshow(orig_img)\n",
        "       plt.savefig(filename, dpi=500, bbox_inches='tight',pad_inches=0)\n",
        "       plt.close()\n",
        "       return\n",
        "    fuegoen.append(filename)\n",
        "    #Get weights for all classes from the prediction layer\n",
        "    last_layer_weights = model.layers[-1].get_weights()[0] #Prediction layer\n",
        "    #Get weights for the predicted class.\n",
        "    last_layer_weights_for_pred = last_layer_weights[:, pred_class]\n",
        "\n",
        "    #Upsample/resize the last conv. output to same size as original image\n",
        "    h = int(img.shape[0]/last_conv_output.shape[0])\n",
        "    w = int(img.shape[1]/last_conv_output.shape[1])\n",
        "    upsampled_last_conv_output = scipy.ndimage.zoom(last_conv_output, (h, w, 1), order=1)\n",
        "    \n",
        "    heat_map = np.dot(upsampled_last_conv_output.reshape((img.shape[0]*img.shape[1], 512)), \n",
        "                 last_layer_weights_for_pred).reshape(img.shape[0],img.shape[1])\n",
        "    \n",
        "    #Since we have a lot of dark pixels where the edges may be thought of as \n",
        "    #high anomaly, let us drop all heat map values in this region to 0.\n",
        "    # #This is an optional step based on the image. \n",
        "    # heat_map[img[:,:,0] == 0] = 0  #All dark pixels outside the object set to 0\n",
        "\n",
        "\n",
        "    #Detect peaks (hot spots) in the heat map. We will set it to detect maximum 5 peaks.\n",
        "    #with rel threshold of 0.5 (compared to the max peak). \n",
        "    peak_coords = peak_local_max(heat_map, num_peaks=5, threshold_rel=0.5, min_distance=10) \n",
        "    plt.imshow(orig_img)\n",
        "    # plt.imshow(heat_map, cmap='jet', alpha=0.20)\n",
        "    for i in range(0,peak_coords.shape[0]):\n",
        "        y = peak_coords[i,0]\n",
        "        x = peak_coords[i,1]\n",
        "        plt.gca().add_patch(Rectangle((x-25, y-25), 50,50,linewidth=1,edgecolor='r',facecolor='none'))\n",
        "\n",
        "    plt.savefig(filename, dpi=500, bbox_inches='tight',pad_inches=0)\n",
        "    \n",
        "    # Here we close the image because otherwise we get a warning saying that the image stays\n",
        "    # open and consumes memory\n",
        "    plt.close()\n",
        "    \n",
        "    return"
      ],
      "metadata": {
        "id": "pVzCDbT1chlR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img = cv2.imread('/content/drive/MyDrive/Fire Dataset PCD/Train/Fire/77.jpg', 1)\n",
        "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "img = Image.fromarray(img, 'RGB')\n",
        "img = img.resize((224, 224))\n",
        "img = np.array(img)\n",
        "plt.imshow(img)"
      ],
      "metadata": {
        "id": "YoUZvuksY11L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_tensor = np.expand_dims(img, axis=0)\n",
        "preprocessed_img = preprocess_input(img_tensor)\n",
        "preprocessed_img = np.squeeze(preprocessed_img)\n",
        "heat_map =plot_heatmap('0',img,preprocessed_img)"
      ],
      "metadata": {
        "id": "PXZHiIhEY9nh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "vidcap = cv2.VideoCapture('/content/drive/MyDrive/test2.mp4')\n",
        "success, image = vidcap.read()\n",
        "count = 0\n",
        "while success:\n",
        "  cv2.imwrite(\"/content/fotos/%d.jpg\" % count, image)    \n",
        "  success, image = vidcap.read()\n",
        "  if count%200 == 0:\n",
        "    print('Saved image ', count)\n",
        "  count += 1\n",
        "print(count)\n"
      ],
      "metadata": {
        "id": "evE3ARbfDOo8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "video_gen=datagen.flow_from_directory(\n",
        "    directory='/content/a/',\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False,\n",
        "    target_size= target_size)"
      ],
      "metadata": {
        "id": "wDAS5hcaDF9G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds = model.predict(video_gen)"
      ],
      "metadata": {
        "id": "sL2DzidoEqbi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Genera imagenes con las predicciones y last_convs\n",
        "fig = plt.figure(figsize=[1,1])\n",
        "# This is to get rid of the axes and only get the picture \n",
        "ax = fig.add_subplot(111)\n",
        "ax.axes.get_xaxis().set_visible(False)\n",
        "ax.axes.get_yaxis().set_visible(False)\n",
        "ax.set_frame_on(False)\n",
        "#Get output from the last conv. layer\n",
        "fuegoen=[]\n",
        "for i in range(len(preds)):\n",
        "  pred,last_conv_output = preds\n",
        "  last_conv_output = np.squeeze(last_conv_output)\n",
        "  pred_class = np.argmax(pred)\n",
        "  if pred_class == 1:\n",
        "      plt.imshow(orig_img)\n",
        "      plt.savefig(filename, dpi=500, bbox_inches='tight',pad_inches=0)\n",
        "      plt.close()\n",
        "  else:\n",
        "    fuegoen.append(filename)\n",
        "    #Get weights for all classes from the prediction layer\n",
        "    last_layer_weights = model.layers[-1].get_weights()[0] #Prediction layer\n",
        "    #Get weights for the predicted class.\n",
        "    last_layer_weights_for_pred = last_layer_weights[:, pred_class]\n",
        "\n",
        "    #Upsample/resize the last conv. output to same size as original image\n",
        "    h = int(img.shape[0]/last_conv_output.shape[0])\n",
        "    w = int(img.shape[1]/last_conv_output.shape[1])\n",
        "    upsampled_last_conv_output = scipy.ndimage.zoom(last_conv_output, (h, w, 1), order=1)\n",
        "\n",
        "    heat_map = np.dot(upsampled_last_conv_output.reshape((img.shape[0]*img.shape[1], 512)), \n",
        "                  last_layer_weights_for_pred).reshape(img.shape[0],img.shape[1])\n",
        "\n",
        "    # #Since we have a lot of dark pixels where the edges may be thought of as \n",
        "    # #high anomaly, let us drop all heat map values in this region to 0.\n",
        "    # #This is an optional step based on the image. \n",
        "    # heat_map[img[:,:,0] == 0] = 0  #All dark pixels outside the object set to 0\n",
        "\n",
        "    #Detect peaks (hot spots) in the heat map. We will set it to detect maximum 5 peaks.\n",
        "    #with rel threshold of 0.5 (compared to the max peak). \n",
        "    peak_coords = peak_local_max(heat_map, num_peaks=5, threshold_rel=0.5, min_distance=10) \n",
        "    plt.imshow(orig_img)\n",
        "    # plt.imshow(heat_map, cmap='jet', alpha=0.20)\n",
        "    for i in range(0,peak_coords.shape[0]):\n",
        "        y = peak_coords[i,0]\n",
        "        x = peak_coords[i,1]\n",
        "        plt.gca().add_patch(Rectangle((x-25, y-25), 50,50,linewidth=1,edgecolor='r',facecolor='none'))\n",
        "\n",
        "    plt.savefig(filename, dpi=500, bbox_inches='tight',pad_inches=0)\n",
        "\n",
        "    # Here we close the image because otherwise we get a warning saying that the image stays\n",
        "    # open and consumes memory\n",
        "    plt.close()\n",
        "\n"
      ],
      "metadata": {
        "id": "izfQyF0uFOS3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "vidcap = cv2.VideoCapture('/content/drive/MyDrive/test2.mp4')\n",
        "success, image = vidcap.read()\n",
        "count = 0\n",
        "while success:\n",
        "  # image = np.resize(image,(224, 224))\n",
        "  image = Image.fromarray(image, 'RGB')\n",
        "  image = image.resize((224, 224))\n",
        "  image = np.array(image)\n",
        "  # plt.imshow(image)\n",
        "  img_tensor = np.expand_dims(image, axis=0)\n",
        "  preprocessed_img = preprocess_input(img_tensor)\n",
        "  preprocessed_img = np.squeeze(preprocessed_img)\n",
        "  plot_heatmap('/content/result/'+str(count),image,preprocessed_img)\n",
        "  # cv2.imwrite(\"/content/video_images4/image_%d.jpg\" % count, image)    \n",
        "  success, image = vidcap.read()\n",
        "  if count%20 == 0:\n",
        "    print('Saved image ', count)\n",
        "  count += 1\n",
        "\n"
      ],
      "metadata": {
        "id": "CMRPHshshaal"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fuegoen"
      ],
      "metadata": {
        "id": "YtRLCcWn_K7v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import os\n",
        "\n",
        "image_folder = '/content/result'\n",
        "video_name = 'final.avi'\n",
        "\n",
        "images = [img for img in os.listdir(image_folder) if img.endswith(\".png\")]\n",
        "len_images = len(images)\n",
        "frame = cv2.imread(os.path.join(image_folder, images[0]))\n",
        "height, width, layers = frame.shape\n",
        "\n",
        "video = cv2.VideoWriter(video_name, cv2.VideoWriter_fourcc(*'DIVX'), 30, (width,height))\n",
        "\n",
        "i = 0\n",
        "for image in images:\n",
        "    video.write(cv2.imread(os.path.join(image_folder, str(i)+'.png')))\n",
        "    i+=1\n",
        "\n",
        "cv2.destroyAllWindows()\n",
        "video.release()"
      ],
      "metadata": {
        "id": "gLB1XsAtp8Vf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}