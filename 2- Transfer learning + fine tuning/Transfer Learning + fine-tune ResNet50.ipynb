{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1QXVF3ScNQm7UPk1-H-aPP26BDtRR6Iqm","timestamp":1667859585850}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"o_VFh3irFVm6"},"outputs":[],"source":["import numpy as np # linear algebra\n","import matplotlib.pyplot as plt\n","from keras import models, regularizers, layers, optimizers, losses, metrics\n","from keras.models import Sequential\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import GlobalAveragePooling2D, Dense,Dropout\n","# from keras.utils import np_utils, to_categorical\n","from keras.preprocessing.image import ImageDataGenerator\n","# from keras.preprocessing import image\n","from keras.applications import ResNet50\n","from tensorflow.keras.applications.resnet50 import preprocess_input\n","import tensorflow as tf\n","from tensorflow.keras.preprocessing.image import load_img, img_to_array\n","import scipy  #Used to upsample our image\n","from tensorflow.keras.optimizers import Adam, SGD\n","from sklearn.utils.class_weight import compute_class_weight\n","import os\n","import cv2\n","from PIL import Image"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"cR3JIQFH8gLs"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Funciones auxiliares"],"metadata":{"id":"niRbmpbNKIUS"}},{"cell_type":"code","source":["def print_layers(model):\n","  for layer in model.layers:\n","    print(layer.name,layer.trainable)\n","\n","def plot_history(history):\n","  #plot the training and validation accuracy and loss at each epoch\n","  loss = history.history['loss']\n","  val_loss = history.history['val_loss']\n","  epochs = range(1, len(loss) + 1)\n","  plt.plot(epochs, loss, 'y', label='Training loss')\n","  plt.plot(epochs, val_loss, 'r', label='Validation loss')\n","  plt.title('Training and validation loss')\n","  plt.xlabel('Epochs')\n","  plt.ylabel('Loss')\n","  plt.legend()\n","  plt.show()\n","  \n","  acc = history.history['accuracy']\n","  val_acc = history.history['val_accuracy']\n","  plt.plot(epochs, acc, 'y', label='Training acc')\n","  plt.plot(epochs, val_acc, 'r', label='Validation acc')\n","  plt.title('Training and validation accuracy')\n","  plt.xlabel('Epochs')\n","  plt.ylabel('Accuracy')\n","  plt.legend()\n","  plt.show()"],"metadata":{"id":"2iQa6dEMKKNw"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Create model"],"metadata":{"id":"Abs0t7YN-psA"}},{"cell_type":"code","source":["def get_model(input_shape = (224,224,3)):\n","    conv_base = ResNet50(weights = None,#weights='imagenet',\n","                      include_top=False,\n","                      input_shape=input_shape)\n","    x = conv_base.output\n","    x = GlobalAveragePooling2D()(x)\n","    # x = Dense(2048, activation=\"relu\")(x) \n","    # x = Dropout(0.5)(x)\n","    x = Dense(2, activation=\"softmax\")(x)\n","    \n","    model = Model(conv_base.input, x)\n","    model.compile(loss='categorical_crossentropy',\n","                optimizer= optimizers.Adam(learning_rate=1e-5),\n","                metrics=['accuracy'])# internamente detecta la funcion los y usa categorical_accuracy al indicar accuracy\n","    return model\n","\n","model = get_model(input_shape = (224,224,3))\n","print(model.summary())"],"metadata":{"id":"FquRczu0-pNP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Train the model"],"metadata":{"id":"ppySyFDEAqUI"}},{"cell_type":"code","source":["print_layers(model)"],"metadata":{"id":"7rPKyQaYIVQy"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##Create dataset"],"metadata":{"id":"3iwSCWBbIIpU"}},{"cell_type":"code","source":["directory = '/content/drive/MyDrive/FIRE DETECTION/data/Fire Dataset PCD'\n","batch_size = 16\n","target_size = model.layers[0].output_shape[0][1:3]#(224,224)\n","\n","train_datagen = ImageDataGenerator(\n","    # rescale=1./255,\n","    preprocessing_function=preprocess_input,\n","    rotation_range=60,\n","    width_shift_range=0.2,\n","    height_shift_range=0.2,\n","    shear_range=0.2,\n","    zoom_range=0.2,\n","    horizontal_flip=True,\n","    fill_mode='nearest')\n","\n","val_datagen = ImageDataGenerator(\n","    #rescale=1./255,\n","    preprocessing_function=preprocess_input)\n","\n","train_generator=train_datagen.flow_from_directory(\n","    directory=directory + '/Train',\n","    batch_size=batch_size,\n","    shuffle=True,\n","    target_size= target_size,\n","    save_to_dir ='/content/drive/MyDrive/prueba')\n","\n","validation_generator=val_datagen.flow_from_directory(\n","    directory=directory + '/Test',\n","    batch_size=batch_size,\n","    shuffle = False,\n","    target_size= target_size)"],"metadata":{"id":"HsComyCZC17d"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["cls_train = train_generator.classes #labels en train\n","class_names = list(validation_generator.class_indices.keys())\n","class_weight = compute_class_weight(class_weight='balanced',\n","                                    classes=np.unique(cls_train),\n","                                    y=cls_train)\n","class_weight = {i : class_weight[i] for i in range(len(class_weight))}\n","print(class_weight)\n","print(class_names)"],"metadata":{"id":"AHQdwQm8JYz0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##- Transfer learning:"],"metadata":{"id":"sfuhAbb3AvRZ"}},{"cell_type":"code","source":["def setup_to_transfer_learning(model):\n","  \"\"\"Freeze all layers and compile the model\"\"\"\n","  for layer in model.layers[:-4]:\n","    layer.trainable = False\n","  for layer in model.layers[-4:]:\n","    layer.trainable = True\n","  model.compile(optimizer='rmsprop', #optimizer=Adam(learning_rate=1e-5),   \n","                loss='categorical_crossentropy', \n","                metrics=['accuracy'])\n","  print(\"model compiled for transfer\")\n","  # print(model.summary())  "],"metadata":{"id":"Z8y9bxHyA7xN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["setup_to_transfer_learning(model)\n","print_layers(model)"],"metadata":{"id":"HFWYysFsEM1-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Include the epoch in the file name (uses `str.format`)\n","ckpt_dir = '/content/drive/MyDrive/FIRE DETECTION/models/ResNet transfer learning'\n","checkpoint_path = os.path.join(ckpt_dir,\"weights-improvement-{epoch:02d}-{val_accuracy:.2f}.ckpt\")\n","\n","# Create a callback that saves the model's weights every epochs\n","cp_callback = tf.keras.callbacks.ModelCheckpoint(\n","    filepath=checkpoint_path, \n","    verbose=1,\n","    monitor='val_accuracy',\n","    mode='max',\n","    save_best_only=True,\n","    save_weights_only=True)\n","\n","# # Save the weights using the `checkpoint_path` format\n","# model.save_weights(checkpoint_path.format(epoch=0))\n","\n","history = model.fit(train_generator,\n","                    epochs=5,\n","                    callbacks=[cp_callback],\n","                    steps_per_epoch = train_generator.samples // batch_size,\n","                    class_weight = class_weight,\n","                    validation_data = validation_generator,\n","                    validation_steps = validation_generator.samples // batch_size,\n","                    verbose = 1)\n","\n","plot_history(history)"],"metadata":{"id":"wuKkxtPEJvDN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##- Fine-tuning:"],"metadata":{"id":"GUVFKGl4A2qx"}},{"cell_type":"code","source":["def setup_to_finetune(model):\n","  for layer in model.layers[-4:]:\n","    layer.trainable = True\n","  for layer in model.layers[:-4]:\n","    if ('conv5' not in layer.name):# and ('block4' not in layer.name):\n","      layer.trainable = False \n","    else:\n","      layer.trainable = True\n","  model.compile(optimizer=Adam(learning_rate=1e-7),   \n","                loss='categorical_crossentropy',\n","                metrics=['accuracy'])\n","  print(\"model compiled\")\n","  # print(model.summary())\n","  # model.compile(loss='categorical_crossentropy',\n","  #                 optimizer= optimizers.Adam(learning_rate=1e-5),\n","  #                 metrics=['accuracy'])\n"],"metadata":{"id":"a6un53vEAnkJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["setup_to_finetune(model)\n","print_layers(model)"],"metadata":{"id":"xV9gqJqKHblx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Include the epoch in the file name (uses `str.format`)\n","ckpt_dir = '/content/drive/MyDrive/FIRE DETECTION/models/sctach resnet'\n","checkpoint_path = os.path.join(ckpt_dir,\"weights-improvement-{epoch:02d}-{val_accuracy:.2f}.ckpt\")\n","\n","# Create a callback that saves the model's weights every epochs\n","cp_callback = tf.keras.callbacks.ModelCheckpoint(\n","    filepath=checkpoint_path, \n","    verbose=1,\n","    monitor='val_accuracy',\n","    mode='max',\n","    save_best_only=True,\n","    save_weights_only=True)\n","\n","history = model.fit(train_generator,\n","                    epochs=50,\n","                    callbacks=[cp_callback],\n","                    steps_per_epoch = train_generator.samples // batch_size,\n","                    class_weight = class_weight,\n","                    validation_data = validation_generator,\n","                    validation_steps = validation_generator.samples // batch_size,\n","                    verbose = 1)\n","\n","plot_history(history)"],"metadata":{"id":"DvpAgeNONvZq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##Evalua modelo"],"metadata":{"id":"NCRSPVS1Txia"}},{"cell_type":"code","source":["test_loss, test_acc = model.evaluate(validation_generator, steps= validation_generator.samples // batch_size, verbose=1)\n","print('test acc:', test_acc)"],"metadata":{"id":"Wl34-dH2TzbL"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Cargar modelo"],"metadata":{"id":"LDsjND9DS82F"}},{"cell_type":"code","source":["model_path = '/content/drive/MyDrive/FIRE DETECTION/models/sctach resnet'\n","os.listdir(model_path)"],"metadata":{"id":"D8qh0iRMhiob"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Cargar modelo dado el path\n","def load_model(model_path,model_name):\n","  model = get_model()\n","  model.load_weights(os.path.join(model_path,model_name))\n","  return model"],"metadata":{"id":"px4eASfOcenc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Cargar ultimo modelo creado\n","def load_last_model(model_path):\n","  latest = tf.train.latest_checkpoint(model_path)\n","  print('last: ',latest)\n","  # Create a new model instance\n","  model = get_model()\n","  model.load_weights(latest)\n","  return model"],"metadata":{"id":"9Nd8P7AthZ-3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["a = load_model('/content/drive/MyDrive/FIRE DETECTION/models/sctach resnet','weights-improvement-10-0.83.ckpt')"],"metadata":{"id":"kjg5Ignq8Ukd"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Evalua modelo cargado"],"metadata":{"id":"pap7rl_ZcLoQ"}},{"cell_type":"code","source":["test_loss, test_acc = model.evaluate(validation_generator, steps= validation_generator.samples // batch_size, verbose=1)\n","print('test acc:', test_acc)"],"metadata":{"id":"odOI_QpzcKRd"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Predict"],"metadata":{"id":"orZj8os1VJRj"}},{"cell_type":"code","source":["idx_out_con_layer = -5 # -6 :SALIDA DE conv5_block3_add (ANTES de relu), o -5, que es la salida de relu y la entrada a global average pooling\n","class_names = ['Fuego','No fuego']\n","last_layer_weights = model.layers[-1].get_weights()[0] #Get weights for all classes from the prediction layer\n","\n","def process_input_image(image_path):\n","  # loads RGB image as PIL.Image.Image type\n","  img = load_img(image_path, target_size=(224, 224))\n","  # convert PIL.Image.Image type to 3D tensor with shape (224, 224, 3)\n","  x = img_to_array(img)\n","  # convert 3D tensor to 4D tensor with shape (1, 224, 224, 3) and return 4D tensor\n","  x = np.expand_dims(x, axis=0)\n","  # convert RGB -> BGR, subtract mean ImageNet pixel, and return 4D tensor\n","  return preprocess_input(x)\n","\n","def compute_heatmaps(model,image_path,last_layer_weights):\n","  #Get output from the last conv. layer and predictions\n","  resnet = Model(inputs = model.input, outputs = (model.output,model.layers[idx_out_con_layer].output))\n","  input = process_input_image(image_path)\n","  pred,last_conv_output = resnet.predict(input)\n","  pred_class = np.argmax(pred)\n","\n","  last_conv_output = np.squeeze(last_conv_output) # (7,7,2048) -> (1,7,7,2048)\n","  last_layer_weights_for_pred = last_layer_weights[:, pred_class]  #Get weights for the predicted class.\n","\n","  #Upsample/resize the last conv. output to same size as original image\n","  h = int(input.shape[1]/last_conv_output.shape[0])\n","  w = int(input.shape[2]/last_conv_output.shape[1])\n","  upsampled_last_conv_output = scipy.ndimage.zoom(last_conv_output, (h, w, 1), order=1)\n","  heat_map = np.dot(upsampled_last_conv_output.reshape((input.shape[1]*input.shape[2], 2048)), \n","                last_layer_weights_for_pred).reshape(input.shape[1],input.shape[2])\n","  return heat_map,pred,pred_class\n","\n","  # #Detect peaks (hot spots) in the heat map. We will set it to detect maximum 5 peaks.\n","  # #with rel threshold of 0.5 (compared to the max peak). \n","  # peak_coords = peak_local_max(heat_map, num_peaks=10, threshold_rel=0.5, min_distance=10) \n","  # plt.imshow(img_aux)\n","  # plt.imshow(heat_map, cmap='jet', alpha=0.70)\n","  # for i in range(0,peak_coords.shape[0]):\n","  #     y = peak_coords[i,0]\n","  #     x = peak_coords[i,1]\n","  #     plt.gca().add_patch(Rectangle((x-25, y-25), 50,50,linewidth=1,edgecolor='r',facecolor='none'))\n","\n","\n","def predict_and_plot(model,image_path,last_layer_weights,ax1, ax2):\n","  # load image, convert BGR --> RGB, resize image to 224 x 224,\n","  img = cv2.imread(image_path, 1)\n","  img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n","  img = Image.fromarray(img, 'RGB')\n","  img = img.resize((224, 224))\n","  ax1.imshow(img, alpha=1)   # alpha is opacity parameter\n","  # plot image\n","  ax2.imshow(img, alpha=0.5)\n","  # get class activation map\n","  heat_map, pred,pred_class = compute_heatmaps(model,image_path,last_layer_weights)\n","  # plot class activation map\n","  ax2.imshow(heat_map, cmap='jet', alpha=0.5)             # overlay heat map from class activation mapping\n","  title = class_names[pred_class] + ':    ' + str(pred[0][pred_class])\n","  ax2.set_title(title)\n","\n","def plot_prediction(file_path,last_layer_weights):\n","  fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, sharey=True, sharex=True, figsize=plt.figaspect(0.5))\n","  predict_and_plot(model,file_path,last_layer_weights,ax1,ax2)\n","  plt.show()\n","\n","\n"],"metadata":{"id":"a-20clLYIxJ0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plot_prediction('/content/drive/MyDrive/FIRE DETECTION/data/Fire Dataset PCD/Test/Fire/image_23.jpg',last_layer_weights)"],"metadata":{"id":"m8A4EFyRorvg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, sharey=True, sharex=True, figsize=plt.figaspect(0.5))\n","predict_and_plot(model,'/content/drive/MyDrive/FIRE DETECTION/data/Fire Dataset PCD/Test/Fire/image_23.jpg',last_layer_weights,ax1,ax2)\n","plt.show()"],"metadata":{"id":"p8FQCvleg3y-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["predict_path = '/content/drive/MyDrive/FIRE DETECTION/data/Fire Dataset PCD/Train/Fire'\n","\n","class_names = ['Fuefo','No fuego']\n","last_layer_weights = model.layers[-1].get_weights()[0] #Get weights for all classes from the prediction layer\n","for filename in os.listdir(predict_path)[15:20]:\n","  filename = os.path.join(predict_path,filename)\n","  plot_prediction(filename,last_layer_weights)\n"],"metadata":{"id":"rpSfEFPCeoZG"},"execution_count":null,"outputs":[]}]}