{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNwdjHHSW64v4m5eMX4p1WE"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import numpy as np # linear algebra\n","import matplotlib.pyplot as plt\n","from keras import models, regularizers, layers, optimizers, losses, metrics\n","from keras.models import Sequential\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import GlobalAveragePooling2D, Dense,Dropout\n","# from keras.utils import np_utils, to_categorical\n","from keras.preprocessing.image import ImageDataGenerator\n","# from keras.preprocessing import image\n","from keras.applications import ResNet50\n","from tensorflow.keras.applications.resnet50 import preprocess_input\n","import tensorflow as tf\n","from tensorflow.keras.preprocessing.image import load_img, img_to_array\n","import scipy  #Used to upsample our image\n","from tensorflow.keras.optimizers import Adam, SGD\n","from sklearn.utils.class_weight import compute_class_weight\n","import os\n","import cv2\n","from PIL import Image\n","from google.colab import drive\n","from tensorflow.keras.layers import Conv2D, Activation, MaxPooling2D\n","from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, AveragePooling2D\n","from tensorflow.keras.models import Sequential, Model\n","from keras.metrics import categorical_accuracy\n","drive.mount('/content/drive')"],"metadata":{"id":"I-UrpNWb9Wg3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def print_layers(model):\n","  for layer in model.layers:\n","    print(layer.name,layer.trainable)\n","\n","def plot_history(history):\n","  #plot the training and validation accuracy and loss at each epoch\n","  loss = history.history['loss']\n","  val_loss = history.history['val_loss']\n","  epochs = range(1, len(loss) + 1)\n","  plt.plot(epochs, loss, 'y', label='Training loss')\n","  plt.plot(epochs, val_loss, 'r', label='Validation loss')\n","  plt.title('Training and validation loss')\n","  plt.xlabel('Epochs')\n","  plt.ylabel('Loss')\n","  plt.legend()\n","  plt.show()\n","  \n","  acc = history.history['categorical_accuracy']\n","  val_acc = history.history['val_categorical_accuracy']\n","  plt.plot(epochs, acc, 'y', label='Training acc')\n","  plt.plot(epochs, val_acc, 'r', label='Validation acc')\n","  plt.title('Training and validation accuracy')\n","  plt.xlabel('Epochs')\n","  plt.ylabel('Accuracy')\n","  plt.legend()\n","  plt.show()"],"metadata":{"id":"w-APm0fZ9aDP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def get_model(input_shape = (224,224,3)):\n","  avg_pool_model = Sequential()\n","\n","  avg_pool_model.add(Conv2D(32, (3, 3), input_shape=input_shape))\n","  avg_pool_model.add(Activation('relu'))\n","  avg_pool_model.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","  avg_pool_model.add(Conv2D(32, (3, 3), kernel_initializer = 'he_uniform'))\n","  avg_pool_model.add(Activation('relu'))\n","  avg_pool_model.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","  avg_pool_model.add(Conv2D(64, (3, 3), kernel_initializer = 'he_uniform'))\n","\n","  avg_pool_model.add(GlobalAveragePooling2D())\n","\n","  #avg_pool_model.add(Flatten()) #No need for flattening anymore.\n","  avg_pool_model.add(Dense(1, activation=\"sigmoid\"))\n","\n","  avg_pool_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=[categorical_accuracy])\n","  return avg_pool_model\n","\n","\n","model = get_model(input_shape = (224,224,3))\n","print(model.summary())"],"metadata":{"id":"YbBfhNGe9gGw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["directory = '/content/drive/MyDrive/FIRE DETECTION/data/Fire Dataset PCD'\n","batch_size = 16\n","target_size = (224,224)\n","\n","train_datagen = ImageDataGenerator(\n","    rescale=1./255,\n","    rotation_range=60,\n","    width_shift_range=0.2,\n","    height_shift_range=0.2,\n","    shear_range=0.2,\n","    zoom_range=0.2,\n","    horizontal_flip=True,\n","    fill_mode='nearest')\n","\n","val_datagen = ImageDataGenerator(rescale=1./255)\n","\n","train_generator=train_datagen.flow_from_directory(\n","    directory=directory + '/Train',\n","    batch_size=batch_size,\n","    shuffle=True,\n","    target_size= target_size)\n","    # save_to_dir ='/content/drive/MyDrive/prueba')\n","\n","validation_generator=val_datagen.flow_from_directory(\n","    directory=directory + '/Test',\n","    batch_size=batch_size,\n","    shuffle = False,\n","    target_size= target_size)"],"metadata":{"id":"VSzpaqYf-ax1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["cls_train = train_generator.classes #labels en train\n","class_names = list(validation_generator.class_indices.keys())\n","class_weight = compute_class_weight(class_weight='balanced',\n","                                    classes=np.unique(cls_train),\n","                                    y=cls_train)\n","class_weight = {i : class_weight[i] for i in range(len(class_weight))}\n","print(class_weight)\n","print(class_names)"],"metadata":{"id":"bwKwvZSb-nKf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Include the epoch in the file name (uses `str.format`)\n","\n","ckpt_dir = '/content/drive/MyDrive/FIRE DETECTION/models/ResNet transfer learning'\n","checkpoint_path = os.path.join(ckpt_dir,\"weights-improvement-{epoch:02d}-{val_categorical_accuracy:.2f}.ckpt\")\n","\n","# Create a callback that saves the model's weights every epochs\n","cp_callback = tf.keras.callbacks.ModelCheckpoint(\n","    filepath=checkpoint_path, \n","    verbose=1,\n","    monitor='val_categorical_accuracy',\n","    mode='max',\n","    save_best_only=True,\n","    save_weights_only=True)\n","    #save_freq=5*batch_size)\n","\n","# # Save the weights using the `checkpoint_path` format\n","# model.save_weights(checkpoint_path.format(epoch=0))\n","\n","history = model.fit(train_generator,\n","                    epochs=5,\n","                    callbacks=[cp_callback],\n","                    steps_per_epoch = train_generator.samples // batch_size,\n","                    class_weight = class_weight,\n","                    validation_data = validation_generator,\n","                    validation_steps = validation_generator.samples // batch_size,\n","                    verbose = 1)\n","\n","plot_history(history)"],"metadata":{"id":"2wQUvCPN9pfF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plot_history(history)"],"metadata":{"id":"2NC_1pztNnOx"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Predict"],"metadata":{"id":"orZj8os1VJRj"}},{"cell_type":"code","source":["model.summary()"],"metadata":{"id":"FhJHIAWSDKrf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["idx_out_con_layer = -3 #\n","class_names = ['Fuego','No fuego']\n","last_layer_weights = model.layers[-1].get_weights()[0] #Get weights for all classes from the prediction layer\n","\n","def process_input_image(image_path):\n","  # loads RGB image as PIL.Image.Image type\n","  img = load_img(image_path, target_size=(224, 224))\n","  # convert PIL.Image.Image type to 3D tensor with shape (224, 224, 3)\n","  x = img_to_array(img)\n","  x = x/255.0\n","  # convert 3D tensor to 4D tensor with shape (1, 224, 224, 3) and return 4D tensor\n","  x = np.expand_dims(x, axis=0)\n","  return x\n","\n","def compute_heatmaps(model,image_path,last_layer_weights):\n","  #Get output from the last conv. layer and predictions\n","  resnet = Model(inputs = model.input, outputs = (model.output,model.layers[idx_out_con_layer].output))\n","  input = process_input_image(image_path)\n","  pred,last_conv_output = resnet.predict(input)\n","  #pred represents the probability that the item is the class encoded as 1 in the data\n","  if pred[0][0] > 0.5:\n","    pred_class = 1\n","  else:\n","    pred_class = 0\n","  last_conv_output = np.squeeze(last_conv_output) # (7,7,2048) -> (1,7,7,2048)\n","  last_layer_weights_for_pred = last_layer_weights[:, 0] \n","\n","  #Upsample/resize the last conv. output to same size as original image\n","  h = int(input.shape[1]/last_conv_output.shape[0])\n","  w = int(input.shape[2]/last_conv_output.shape[1])\n","  upsampled_last_conv_output = scipy.ndimage.zoom(last_conv_output, (h, w, 1), order=1)\n","\n","  # heat_map = np.dot(upsampled_last_conv_output.reshape((input.shape[1]*input.shape[2], 2048)), \n","  #               last_layer_weights_for_pred).reshape(input.shape[1],input.shape[2])\n","  heat_map = np.dot(upsampled_last_conv_output, last_layer_weights_for_pred)\n","\n","  return heat_map,pred,pred_class\n","\n","  # #Detect peaks (hot spots) in the heat map. We will set it to detect maximum 5 peaks.\n","  # #with rel threshold of 0.5 (compared to the max peak). \n","  # peak_coords = peak_local_max(heat_map, num_peaks=10, threshold_rel=0.5, min_distance=10) \n","  # plt.imshow(img_aux)\n","  # plt.imshow(heat_map, cmap='jet', alpha=0.70)\n","  # for i in range(0,peak_coords.shape[0]):\n","  #     y = peak_coords[i,0]\n","  #     x = peak_coords[i,1]\n","  #     plt.gca().add_patch(Rectangle((x-25, y-25), 50,50,linewidth=1,edgecolor='r',facecolor='none'))\n","\n","\n","def predict_and_plot(model,image_path,last_layer_weights,ax1, ax2):\n","  # load image, convert BGR --> RGB, resize image to 224 x 224,\n","  img = cv2.imread(image_path, 1)\n","  img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n","  img = Image.fromarray(img, 'RGB')\n","  img = img.resize((224, 224))\n","  ax1.imshow(img, alpha=1)   # alpha is opacity parameter\n","  # plot image\n","  ax2.imshow(img, alpha=0.5)\n","  # get class activation map\n","  heat_map, pred,pred_class = compute_heatmaps(model,image_path,last_layer_weights)\n","  # plot class activation map\n","  ax2.imshow(heat_map, cmap='jet', alpha=0.5)# overlay heat map from class activation mapping\n","\n"," \n","  title = class_names[pred_class] + '    Prob de fuego:  ' + str(1-pred[0][0])\n","  ax2.set_title(title)\n","\n","def plot_prediction(file_path,last_layer_weights):\n","  fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, sharey=True, sharex=True, figsize=plt.figaspect(0.5))\n","  predict_and_plot(model,file_path,last_layer_weights,ax1,ax2)\n","  plt.show()"],"metadata":{"id":"a-20clLYIxJ0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plot_prediction('/content/drive/MyDrive/FIRE DETECTION/data/Fire Dataset PCD/Test/Fire/100.jpg',last_layer_weights)"],"metadata":{"id":"m8A4EFyRorvg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["predict_path = '/content/drive/MyDrive/FIRE DETECTION/data/Fire Dataset PCD/Train/Fire'\n","\n","class_names = ['Fuefo','No fuego']\n","last_layer_weights = model.layers[-1].get_weights()[0] #Get weights for all classes from the prediction layer\n","for filename in os.listdir(predict_path)[15:20]:\n","  filename = os.path.join(predict_path,filename)\n","  plot_prediction(filename,last_layer_weights)\n"],"metadata":{"id":"rpSfEFPCeoZG"},"execution_count":null,"outputs":[]}]}